## üìù Tabela de Conte√∫dos

* [Sobre](#sobre)
* [Come√ßando](#comecando)
* [Instala√ß√£o do MongoDB Compass no Ubuntu](#instalacao-mongodb-compass-ubuntu)
* [Instala√ß√£o do Another Redis Desktop Manager no Ubuntu](#instalacao-ardm-ubuntu)
* [Implanta√ß√£o](#implantacao)
* [Uso](#uso)
* [Constru√≠do Usando](#construido_usando)
* [Contribuindo](#contribuindo)
* [Autores](#autores)

## üßê Sobre <a name="sobre"></a>


Este projeto configura um ambiente completo para executar o n8n, uma poderosa ferramenta de automa√ß√£o de fluxos de trabalho. Ele utiliza o Docker Compose para facilitar a configura√ß√£o e o gerenciamento dos servi√ßos necess√°rios. O MongoDB √© utilizado para armazenar os dados do n8n de forma persistente, garantindo que seus fluxos de trabalho e configura√ß√µes sejam preservados entre reinicializa√ß√µes. O Redis √© empregado para otimizar o desempenho do n8n, gerenciando filas de tarefas e fornecendo um mecanismo de cache eficiente.

Al√©m disso, esta configura√ß√£o inclui um stack de logs (Elasticsearch, Logstash e Kibana) para coletar, armazenar e visualizar centralizadamente os logs de todos os seus servi√ßos. Isso √© crucial para depura√ß√£o, monitoramento e compreens√£o do comportamento do seu assistente. Esta configura√ß√£o permite que voc√™ aproveite ao m√°ximo os recursos do n8n em um ambiente robusto, escal√°vel e observ√°vel.

üèÅ Come√ßando <a name="comecando"></a>

Estas instru√ß√µes ir√£o ajud√°-lo a obter uma c√≥pia do projeto em execu√ß√£o na sua m√°quina local para fins de desenvolvimento e teste. Veja implanta√ß√£o para notas sobre como implantar o projeto em um sistema ativo.

Pr√©-requisitos
Voc√™ precisa ter o Docker e o Docker Compose instalados na sua m√°quina.

Bash

# Exemplo para verificar a instala√ß√£o do Docker
docker --version

# Exemplo para verificar a instala√ß√£o do Docker Compose
docker-compose --version
Instalando
Siga estes passos para configurar o ambiente de desenvolvimento:

Crie a estrutura de pastas e arquivos:
Na pasta raiz do seu projeto, crie a seguinte estrutura:

.
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ logstash/
    ‚îî‚îÄ‚îÄ config/
        ‚îî‚îÄ‚îÄ logstash.conf
Preencha o arquivo docker-compose.yml:
Cole o conte√∫do abaixo no seu arquivo docker-compose.yml:

YAML

version: '3.8'

services:
  # --- N8N Core Services ---
  n8n:
    image: n8nio/n8n:latest # Usando a vers√£o mais recente
    container_name: n8n_core_app
    ports:
      - "5678:5678"
    volumes:
      - n8n_data:/home/node/.n8n # Volume persistente para dados do n8n
    environment:
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=${N8N_PORT:-5678}
      - N8N_PROTOCOL=${N8N_PROTOCOL:-http}
      - NODE_ENV=production
      - N8N_DB=mongodb
      - N8N_DB_MONGODB_URL=mongodb://n8n_mongo_db:27017/n8n # Conecta ao servi√ßo MongoDB
      - REDIS_HOST=n8n_redis_cache # Conecta ao servi√ßo Redis
      - N8N_LOG_LEVEL=info # N√≠vel de log do n8n (info, debug, warn, error)
      - N8N_LOG_OUTPUT=stdout # N8N envia logs para a sa√≠da padr√£o para o Docker capturar
    restart: unless-stopped
    networks:
      - assistant_network # Adiciona √† rede customizada
    logging: # Configura o driver de log do Docker para GELF
      driver: gelf
      options:
        gelf-address: "udp://logstash_gelf:12201" # Aponta para o servi√ßo Logstash
        tag: "n8n" # Tag para identificar os logs no Logstash/Elasticsearch

  n8n_mongo_db:
    image: mongo:latest
    container_name: n8n_mongo_db_data
    restart: unless-stopped
    volumes:
      - n8n_mongo_data:/data/db # Volume persistente para dados do MongoDB
    networks:
      - assistant_network
    logging:
      driver: gelf
      options:
        gelf-address: "udp://logstash_gelf:12201"
        tag: "n8n-mongo"

  n8n_redis_cache:
    image: redis:latest
    container_name: n8n_redis_cache_data
    restart: unless-stopped
    volumes:
      - n8n_redis_data:/data # Volume persistente para dados do Redis
    networks:
      - assistant_network
    logging:
      driver: gelf
      options:
        gelf-address: "udp://logstash_gelf:12201"
        tag: "n8n-redis"

  # --- ELK Stack Services for Logging ---
  elasticsearch_log:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4 # Vers√£o recomendada
    container_name: elasticsearch_log_data
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false # ATEN√á√ÉO: N√ÉO USE EM PRODU√á√ÉO SEM CONFIGURAR A SEGURAN√áA!
      - ES_JAVA_OPTS=-Xms512m -Xmx512m # Aloca 512MB de RAM. Ajuste conforme sua m√°quina.
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data # Volume persistente para dados do ES
    ports:
      - "9200:9200" # Porta da API REST do Elasticsearch
    restart: unless-stopped
    networks:
      - assistant_network

  logstash_gelf:
    image: docker.elastic.co/logstash/logstash:8.13.4 # Mesma vers√£o principal do ES
    container_name: logstash_gelf_processor
    command: logstash -f /usr/share/logstash/config/logstash.conf # Aponta para o arquivo de config
    volumes:
      - ./logstash/config:/usr/share/logstash/config # Monta o diret√≥rio de config
    ports:
      - "12201:12201/udp" # Porta para receber logs GELF via UDP
    environment:
      - LS_JAVA_OPTS=-Xms256m -Xmx256m # Aloca 256MB de RAM. Ajuste conforme necess√°rio.
    depends_on:
      - elasticsearch_log # Inicia depois do Elasticsearch
    restart: unless-stopped
    networks:
      - assistant_network
    logging: # Desabilita o driver padr√£o de logging do docker para evitar loop de logs do logstash
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  kibana_viewer:
    image: docker.elastic.co/kibana/kibana:8.13.4 # Mesma vers√£o principal do ES e Logstash
    container_name: kibana_log_viewer
    ports:
      - "5601:5601" # Porta do Kibana UI
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch_log:9200 # Conecta ao Elasticsearch usando o novo nome do servi√ßo
      - XPACK_SECURITY_ENABLED=false # ATEN√á√ÉO: N√ÉO USE EM PRODU√á√ÉO SEM CONFIGURAR A SEGURAN√áA!
    depends_on:
      - elasticsearch_log # Inicia depois do Elasticsearch
    restart: unless-stopped
    networks:
      - assistant_network

# --- Volumes para persist√™ncia de dados ---
volumes:
  n8n_data:
  n8n_mongo_data:
  n8n_redis_data:
  elasticsearch_data:

# --- Rede customizada para comunica√ß√£o entre os servi√ßos ---
networks:
  assistant_network:
    name: personal_ai_assistant_network
Crie e Preencha o arquivo logstash/config/logstash.conf:
Cole o conte√∫do abaixo no seu arquivo logstash/config/logstash.conf:

# logstash/config/logstash.conf
input {
  gelf {
    port => 12201 # Porta para receber logs GELF
    codec => json
  }
}

filter {
  # O GELF j√° estrutura bem os logs, mas voc√™ pode adicionar filtros para parsear
  # campos espec√≠ficos ou enriquecer os dados se necess√°rio.
  # Exemplo: Renomear o campo 'host' para algo mais descritivo
  # mutate {
  #   rename => { "host" => "docker_container_host" }
  # }
}

output {
  elasticsearch {
    hosts => ["elasticsearch_log:9200"] # Aponta para o servi√ßo Elasticsearch
    index => "personal-ai-assistant-logs-%{+YYYY.MM.dd}" # √çndice di√°rio no Elasticsearch
  }
  # Para depura√ß√£o, descomente a linha abaixo para ver os logs no terminal do Logstash
  # stdout { codec => rubydebug }
}
Inicie os Cont√™ineres:
No terminal, na pasta onde est√° seu docker-compose.yml, execute:

Bash

docker compose up -d
Este comando ir√° iniciar todos os cont√™ineres: n8n, MongoDB, Redis, Elasticsearch, Logstash e Kibana.

Acesse o n8n no seu navegador:
Abra http://localhost:5678 no seu navegador.

Instala√ß√£o do MongoDB Compass no Ubuntu <a name="instalacao-mongodb-compass-ubuntu"></a>
O MongoDB Compass √© uma GUI para o MongoDB. Ele pode ser instalado no Ubuntu da seguinte forma:

Importe a chave GPG p√∫blica do MongoDB:

Bash

wget -qO - https://www.mongodb.org/static/pgp/server-5.0.asc | sudo apt-key add -
Crie uma lista de fontes para o MongoDB:

Bash

echo "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/5.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-5.0.list
Substitua focal pela sua vers√£o do Ubuntu, se necess√°rio (e.g., bionic, groovy, hirsute). Verifique a vers√£o correta em https://www.mongodb.com/docs/manual/tutorial/install-mongodb-on-ubuntu/

ReCarregue o cache do pacote:

Bash

sudo apt update
Instale o MongoDB Compass:

Bash

sudo apt install mongodb-compass
Execute o MongoDB Compass:

Bash

mongocompass
Instala√ß√£o do Another Redis Desktop Manager no Ubuntu <a name="instalacao-ardm-ubuntu"></a>
Another Redis Desktop Manager (ARDM) √© uma GUI para o Redis. Ele pode ser instalado no Ubuntu da seguinte forma:

Baixe o pacote .deb do ARDM no site do GitHub:

Acesse a p√°gina de lan√ßamentos do ARDM no GitHub: https://github.com/qishibo/AnotherRedisDesktopManager/releases
Encontre a vers√£o mais recente e baixe o arquivo .deb para a sua arquitetura (geralmente amd64).
Instale o pacote .deb usando o dpkg:

Bash

sudo dpkg -i <caminho_do_arquivo_deb>
Substitua <caminho_do_arquivo_deb> pelo caminho do arquivo que voc√™ baixou.

Corrija quaisquer depend√™ncias ausentes:

Bash

sudo apt -f install
Execute o ARDM:

Bash

ardm
üîé Visualizando os Logs com Kibana <a name="visualizando-os-logs-com-kibana"></a>
O Kibana √© a interface de visualiza√ß√£o que permite explorar, analisar e criar dashboards a partir dos logs coletados no Elasticsearch.

Acesse o Kibana no navegador:
Abra http://localhost:5601 no seu navegador.

Crie um "Index Pattern" (Padr√£o de √çndice):
O Kibana precisa de um padr√£o para saber onde buscar os logs no Elasticsearch.

Na barra de navega√ß√£o do Kibana (geralmente √† esquerda), navegue at√© "Stack Management" (ou apenas "Management" em vers√µes mais antigas).
Dentro de "Stack Management", encontre a se√ß√£o "Kibana" e clique em "Index Patterns" (ou "Data Views" em vers√µes mais novas).
Clique em "Create data view" (ou "Create index pattern").
No campo "Index pattern name", digite personal-ai-assistant-logs-*. O asterisco (*) √© um curinga que corresponde a todos os √≠ndices que come√ßam com "personal-ai-assistant-logs-", que √© o que o Logstash est√° criando diariamente (ex: personal-ai-assistant-logs-2025.06.08).
No campo "Timestamp field", selecione @timestamp. Este campo √© crucial para que o Kibana possa organizar os logs cronologicamente.
Clique em "Create data view".
Explore seus Logs no "Discover":
Agora que o padr√£o de √≠ndice est√° configurado, voc√™ pode ver seus logs.

No menu de navega√ß√£o do Kibana, v√° para a se√ß√£o "Analytics" e clique em "Discover".
Certifique-se de que o "Index Pattern" que voc√™ acabou de criar (personal-ai-assistant-logs-*) esteja selecionado no canto superior esquerdo da tela.
Voc√™ ver√° uma lista de todos os logs coletados de seus cont√™ineres Docker (n8n, MongoDB, Redis).
Filtrar Logs: Voc√™ pode usar a barra de pesquisa na parte superior para filtrar logs (ex: digite tag: "n8n" para ver apenas os logs do n8n, ou level: "error" para ver apenas os logs de erro).
Ajustar Intervalo de Tempo: No canto superior direito, voc√™ pode ajustar o intervalo de tempo para ver logs de "√∫ltimos 15 minutos", "√∫ltima hora", "√∫ltimo dia", etc.
Inspecionar Logs: Clique em uma linha de log para expandir e ver todos os campos e detalhes associados √†quela entrada de log.
üîß Executando os testes <a name="testes"></a>
N√£o h√° testes automatizados inclu√≠dos neste projeto espec√≠fico de provisionamento. Este projeto se concentra na configura√ß√£o do ambiente. Os testes para o n8n em si e para o seu assistente de IA devem ser tratados separadamente, seguindo a documenta√ß√£o do n8n e as melhores pr√°ticas de teste para aplica√ß√µes de IA.

üéà Uso <a name="uso"></a>
Depois que o ambiente estiver configurado e todos os servi√ßos estiverem em execu√ß√£o, voc√™ pode:

Acessar o n8n: V√° para http://localhost:5678 para come√ßar a criar e gerenciar seus fluxos de trabalho de automa√ß√£o.
Monitorar Logs: Utilize o Kibana em http://localhost:5601 para ter uma vis√£o centralizada e em tempo real de tudo o que est√° acontecendo nos seus servi√ßos. Isso ser√° fundamental para depurar seus fluxos de trabalho e monitorar o comportamento do assistente.
Gerenciar Dados: Conecte-se ao MongoDB (usando o Compass) e Redis (usando o ARDM) para inspecionar os dados armazenados pelo n8n e, futuramente, os dados do seu assistente (metas, objetivos, di√°rio de bordo).
üöÄ Implanta√ß√£o <a name="implantacao"></a>
Para implantar isso em um sistema ativo (produ√ß√£o), voc√™ pode usar um orquestrador de cont√™ineres como o Kubernetes ou o Docker Swarm. Voc√™ precisar√° provisionar uma infraestrutura com recursos suficientes para executar todos os servi√ßos. Al√©m disso, considere:

Volumes Persistentes: Configurar volumes persistentes para o MongoDB, Redis e Elasticsearch em um armazenamento externo (como NFS, EFS, ou provedores de armazenamento em nuvem) para garantir a durabilidade dos dados e a resili√™ncia contra falhas de hardware.
Reverse Proxy: Um proxy reverso (como Nginx, Caddy ou Traefik) √© altamente recomendado para rotear o tr√°fego para o n8n e o Kibana, adicionando uma camada de seguran√ßa (HTTPS com Let's Encrypt), balanceamento de carga e gerenciamento de dom√≠nio.
Seguran√ßa: Em produ√ß√£o, NUNCA use xpack.security.enabled=false. Configure a seguran√ßa do Elasticsearch/Kibana com usu√°rios e senhas robustos e considere o uso de SSL/TLS para as comunica√ß√µes internas entre os servi√ßos da ELK Stack.
Monitoramento e Alertas: Implemente um monitoramento mais avan√ßado para os recursos dos cont√™ineres (CPU, mem√≥ria, disco) e configure alertas para falhas ou comportamentos anormais.
Backup e Recupera√ß√£o: Crie uma estrat√©gia robusta de backup para todos os volumes de dados persistentes.
‚õèÔ∏è Constru√≠do Usando <a name="construido_usando"></a>
n8n - Plataforma de Automa√ß√£o de Fluxo de Trabalho
MongoDB - Banco de Dados NoSQL
Redis - Armazenamento de Estrutura de Dados em Mem√≥ria (Cache e Message Broker)
Elasticsearch - Motor de Busca e An√°lise Distribu√≠do
Logstash - Pipeline de Processamento de Dados (Coleta, Transforma√ß√£o, Envio)
Kibana - Plataforma de Visualiza√ß√£o e Explora√ß√£o de Dados
Docker - Plataforma de Cont√™ineres
Docker Compose - Ferramenta de Orquestra√ß√£o para M√∫ltiplos Cont√™ineres
ü§ù Contribuindo <a name="contribuindo"></a>
Contribui√ß√µes s√£o o que tornam a comunidade open source um lugar incr√≠vel para aprender, inspirar e criar. Qualquer contribui√ß√£o que voc√™ fizer ser√° muito apreciada.

Fa√ßa um Fork do Projeto
Crie sua Feature Branch (git checkout -b feature/AmazingFeature)
Fa√ßa Commit das suas Mudan√ßas (git commit -m 'Add some AmazingFeature')
Fa√ßa Push para a Branch (git push origin feature/AmazingFeature)
Abra um Pull Request

‚úçÔ∏è Autores <a name="autores"></a>

Guilherme Namura Felix - Desenvolvimento Inicial